[2024-11-18 22:44:01,345 systems.py:197 INFO] Found unknown device in GPU connection topology: NIC0. Skipping.
[2024-11-18 22:44:01,423 main.py:229 INFO] Detected system ID: KnownSystem.sc1
[2024-11-18 22:44:04,158 generate_conf_files.py:107 INFO] Generated measurements/ entries for sc1_TRT/stable-diffusion-xl/Offline
[2024-11-18 22:44:04,158 __init__.py:46 INFO] Running command: python3 -m code.stable-diffusion-xl.tensorrt.harness --logfile_outdir="/home/lry/CM/repos/local/cache/6c0ba4746fa74e77/test_results/mlperf_inference_lry_40-nvidia_original-gpu-tensorrt-vdefault-scc24-main/stable-diffusion-xl/offline/performance/run_1" --logfile_prefix="mlperf_log_" --performance_sample_count=5000 --test_mode="PerformanceOnly" --gpu_batch_size=8 --mlperf_conf_path="/home/lry/CM/repos/local/cache/3e2d12440d5a4a93/inference/mlperf.conf" --tensor_path="build/preprocessed_data/coco2014-tokenized-sdxl/5k_dataset_final/" --use_graphs=true --user_conf_path="/home/lry/CM/repos/mlcommons@cm4mlops/script/generate-mlperf-inference-user-conf/tmp/439f0e338dd148d583e06d0d58caeae3.conf" --gpu_inference_streams=1 --gpu_copy_streams=1 --gpu_engines="./build/engines/sc1/stable-diffusion-xl/Offline/stable-diffusion-xl-CLIP-Offline-gpu-b8-fp16.custom_k_99_MaxP.plan,./build/engines/sc1/stable-diffusion-xl/Offline/stable-diffusion-xl-CLIPWithProj-Offline-gpu-b8-fp16.custom_k_99_MaxP.plan,./build/engines/sc1/stable-diffusion-xl/Offline/stable-diffusion-xl-UNetXL-Offline-gpu-b8-int8.custom_k_99_MaxP.plan,./build/engines/sc1/stable-diffusion-xl/Offline/stable-diffusion-xl-VAE-Offline-gpu-b8-fp32.custom_k_99_MaxP.plan" --scenario Offline --model stable-diffusion-xl
[2024-11-18 22:44:04,158 __init__.py:53 INFO] Overriding Environment
[2024-11-18 22:44:06,925 systems.py:197 INFO] Found unknown device in GPU connection topology: NIC0. Skipping.
2024-11-18 22:44:09,690	INFO worker.py:1567 -- Connecting to existing Ray cluster at address: 10.0.0.1:6379...
2024-11-18 22:44:09,701	INFO worker.py:1743 -- Connected to Ray cluster. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
[2024-11-18 22:44:09,932 harness.py:207 INFO] Start Warm Up!
[36m(SDXLCore pid=218098)[0m [2024-11-18 22:44:14,227 backend.py:428 INFO] initialized
[36m(SDXLCore pid=218098)[0m [2024-11-18 22:44:14,341 backend.py:72 INFO] Loading TensorRT engine: ./build/engines/sc1/stable-diffusion-xl/Offline/stable-diffusion-xl-CLIP-Offline-gpu-b8-fp16.custom_k_99_MaxP.plan.
[36m(SDXLCore pid=218098)[0m [2024-11-18 22:44:14,560 backend.py:72 INFO] Loading TensorRT engine: ./build/engines/sc1/stable-diffusion-xl/Offline/stable-diffusion-xl-CLIPWithProj-Offline-gpu-b8-fp16.custom_k_99_MaxP.plan.
[36m(SDXLCore pid=218098)[0m [2024-11-18 22:44:18,722 backend.py:97 INFO] Enabling cuda graphs for unet
[36m(SDXLCore pid=218098)[0m [2024-11-18 22:44:19,151 backend.py:155 INFO] captured graph for BS=1
[36m(SDXLCore pid=18154, ip=10.0.0.3)[0m [2024-11-18 22:44:12,295 backend.py:428 INFO] initialized[32m [repeated 8x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)[0m
[36m(SDXLCore pid=18154, ip=10.0.0.3)[0m [2024-11-18 22:44:14,350 backend.py:72 INFO] Loading TensorRT engine: ./build/engines/sc1/stable-diffusion-xl/Offline/stable-diffusion-xl-VAE-Offline-gpu-b8-fp32.custom_k_99_MaxP.plan.[32m [repeated 34x across cluster][0m
[36m(SDXLCore pid=218098)[0m [2024-11-18 22:44:19,881 backend.py:155 INFO] captured graph for BS=2
[36m(SDXLCore pid=18154, ip=10.0.0.3)[0m [2024-11-18 22:44:17,245 backend.py:97 INFO] Enabling cuda graphs for unet[32m [repeated 8x across cluster][0m
[36m(SDXLCore pid=18157, ip=10.0.0.3)[0m [2024-11-18 22:44:20,962 backend.py:155 INFO] captured graph for BS=6[32m [repeated 53x across cluster][0m
[2024-11-18 22:44:43,090 harness.py:209 INFO] Warm Up Done!
[2024-11-18 22:44:43,090 harness.py:211 INFO] Start Test!
[2024-11-18 22:44:43,092 backend.py:852 INFO] 504
[36m(SDXLCore pid=218098)[0m [2024-11-18 22:44:43,094 backend.py:630 INFO] generate_images
[36m(SDXLCore pid=218103)[0m [2024-11-18 22:44:25,610 backend.py:155 INFO] captured graph for BS=8[32m [repeated 17x across cluster][0m
[36m(SDXLCore pid=18156, ip=10.0.0.3)[0m [2024-11-18 22:44:47,506 backend.py:630 INFO] generate_images[32m [repeated 9x across cluster][0m
[36m(SDXLCore pid=18156, ip=10.0.0.3)[0m [2024-11-18 22:44:55,160 backend.py:630 INFO] generate_images[32m [repeated 9x across cluster][0m
[36m(SDXLCore pid=18156, ip=10.0.0.3)[0m [2024-11-18 22:45:02,845 backend.py:630 INFO] generate_images[32m [repeated 9x across cluster][0m
[36m(SDXLCore pid=18156, ip=10.0.0.3)[0m [2024-11-18 22:45:10,550 backend.py:630 INFO] generate_images[32m [repeated 9x across cluster][0m
[36m(SDXLCore pid=18156, ip=10.0.0.3)[0m [2024-11-18 22:45:18,248 backend.py:630 INFO] generate_images[32m [repeated 9x across cluster][0m
[36m(SDXLCore pid=18156, ip=10.0.0.3)[0m [2024-11-18 22:45:25,968 backend.py:630 INFO] generate_images[32m [repeated 9x across cluster][0m
[36m(SDXLCore pid=218103)[0m [2024-11-18 22:45:34,404 backend.py:630 INFO] generate_images[32m [repeated 6x across cluster][0m
[2024-11-18 22:45:43,985 backend.py:901 INFO] [Server] Received 504 total samples
[2024-11-18 22:45:43,988 backend.py:911 INFO] [Device 0] Reported 56 samples
[2024-11-18 22:45:43,989 backend.py:911 INFO] [Device 1] Reported 56 samples
[2024-11-18 22:45:43,991 backend.py:911 INFO] [Device 2] Reported 56 samples
[2024-11-18 22:45:43,993 backend.py:911 INFO] [Device 3] Reported 56 samples
[2024-11-18 22:45:43,994 backend.py:911 INFO] [Device 4] Reported 56 samples
[2024-11-18 22:45:43,996 backend.py:911 INFO] [Device 5] Reported 56 samples
[2024-11-18 22:45:43,998 backend.py:911 INFO] [Device 6] Reported 56 samples
[2024-11-18 22:45:43,999 backend.py:911 INFO] [Device 7] Reported 56 samples
[2024-11-18 22:45:44,001 backend.py:911 INFO] [Device 8] Reported 56 samples
[2024-11-18 22:45:44,001 harness.py:214 INFO] Test Done!
[2024-11-18 22:45:44,001 harness.py:216 INFO] Destroying SUT...
[2024-11-18 22:45:44,001 harness.py:219 INFO] Destroying QSL...
[36m(SDXLCore pid=218098)[0m [2024-11-18 22:45:35,109 backend.py:630 INFO] generate_images[32m [repeated 2x across cluster][0m
benchmark : Benchmark.SDXL
buffer_manager_thread_count : 0
data_dir : /home/lry/CM/repos/local/cache/d2b9079c1073417b/data
gpu_batch_size : 8
gpu_copy_streams : 1
gpu_inference_streams : 1
input_dtype : int32
input_format : linear
log_dir : /home/lry/CM/repos/local/cache/3443882dd9374096/repo/closed/NVIDIA/build/logs/2024.11.18-22.43.57
mlperf_conf_path : /home/lry/CM/repos/local/cache/3e2d12440d5a4a93/inference/mlperf.conf
model_path : /home/lry/CM/repos/local/cache/d2b9079c1073417b/models/SDXL/
offline_expected_qps : 0.0
precision : int8
preprocessed_data_dir : /home/lry/CM/repos/local/cache/d2b9079c1073417b/preprocessed_data
scenario : Scenario.Offline
system : SystemConfiguration(host_cpu_conf=CPUConfiguration(layout={CPU(name='AMD EPYC 9684X 96-Core Processor', architecture=<CPUArchitecture.x86_64: AliasedName(name='x86_64', aliases=(), patterns=())>, core_count=96, threads_per_core=2): 2}), host_mem_conf=MemoryConfiguration(host_memory_capacity=Memory(quantity=791.59486, byte_suffix=<ByteSuffix.GB: (1000, 3)>, _num_bytes=791594860000), comparison_tolerance=0.05), accelerator_conf=AcceleratorConfiguration(layout=defaultdict(<class 'int'>, {GPU(name='NVIDIA H100 80GB HBM3', accelerator_type=<AcceleratorType.Discrete: AliasedName(name='Discrete', aliases=(), patterns=())>, vram=Memory(quantity=79.6474609375, byte_suffix=<ByteSuffix.GiB: (1024, 3)>, _num_bytes=85520809984), max_power_limit=700.0, pci_id='0x233010DE', compute_sm=90): 5})), numa_conf=NUMAConfiguration(numa_nodes={}, num_numa_nodes=2), system_id='sc1')
tensor_path : build/preprocessed_data/coco2014-tokenized-sdxl/5k_dataset_final/
test_mode : PerformanceOnly
use_graphs : True
user_conf_path : /home/lry/CM/repos/mlcommons@cm4mlops/script/generate-mlperf-inference-user-conf/tmp/439f0e338dd148d583e06d0d58caeae3.conf
system_id : sc1
config_name : sc1_stable-diffusion-xl_Offline
workload_setting : WorkloadSetting(HarnessType.Custom, AccuracyTarget.k_99, PowerSetting.MaxP)
optimization_level : plugin-enabled
num_profiles : 1
config_ver : custom_k_99_MaxP
accuracy_level : 99%
inference_server : custom
skip_file_checks : False
power_limit : None
cpu_freq : None
[36m(SDXLCore pid=218098)[0m [I] Loading bytes from ./build/engines/sc1/stable-diffusion-xl/Offline/stable-diffusion-xl-CLIP-Offline-gpu-b8-fp16.custom_k_99_MaxP.plan
[36m(SDXLCore pid=218098)[0m [I] Loading bytes from ./build/engines/sc1/stable-diffusion-xl/Offline/stable-diffusion-xl-CLIPWithProj-Offline-gpu-b8-fp16.custom_k_99_MaxP.plan
[36m(SDXLCore pid=18154, ip=10.0.0.3)[0m [I] Loading bytes from ./build/engines/sc1/stable-diffusion-xl/Offline/stable-diffusion-xl-VAE-Offline-gpu-b8-fp32.custom_k_99_MaxP.plan[32m [repeated 34x across cluster][0m
[2024-11-18 22:45:45,443 run_harness.py:166 INFO] Result: result_samples_per_second: 8.2807, Result is VALID
 
======================== Result summaries: ========================

